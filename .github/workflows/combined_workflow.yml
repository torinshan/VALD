name: Workload & Model Pipeline (Every 15 min)

on:
  schedule:
    - cron: "*/15 * * * *"
  workflow_dispatch:
    inputs:
      skip_training:
        description: "Skip model training (ingest only)"
        required: false
        type: boolean
        default: false
      start_date:
        description: "Model training start date (YYYY-MM-DD)"
        required: false
        default: "2025-06-01"
      end_date:
        description: "Model training end date (YYYY-MM-DD)"
        required: false
        default: "2025-12-31"

env:
  # GCP / BigQuery configuration
  GCP_PROJECT: sac-vald-hub
  BQ_DATASET: analytics
  BQ_LOCATION: US

  # BigQuery table names
  WORKLOAD_TABLE: workload_daily
  READINESS_TABLE: vald_fd_jumps
  ROSTER_TABLE: roster_mapping
  PREDICTIONS_TABLE: readiness_predictions_byname

  TEAM_NAME: sacstate-football

jobs:
  ingest:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Auth to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
          create_credentials_file: true
          export_environment_variables: true

      - uses: google-github-actions/setup-gcloud@v2

      - uses: r-lib/actions/setup-r@v2
        with:
          use-public-rspm: true

      - uses: r-lib/actions/setup-r-dependencies@v2
        with:
          cache-version: 1
          extra-packages: |
            any::bigrquery
            any::DBI
            any::dplyr
            any::tidyr
            any::readr
            any::stringr
            any::gargle
            any::glue
            any::jsonlite
            any::httr
            any::curl
            any::janitor
            any::lubridate
            any::slider
            any::tibble
            any::data.table
            any::hms
            any::readxl

      - name: System libs
        run: |
          sudo apt-get update
          sudo apt-get install -y libcurl4-openssl-dev libssl-dev libxml2-dev jq curl

      - name: Sanity check OneDrive link
        env:
          ONEDRIVE_PUBLIC_URL: "https://mysacstate-my.sharepoint.com/:x:/g/personal/torin_shanahan_csus_edu/EfH5izRo81tHiVlwG99DEFsBzjwhTzBzQ_1_hYKgpq_VPA?download=1"
        run: |
          set -euo pipefail
          echo "HEAD:"
          curl -I -L "$ONEDRIVE_PUBLIC_URL" | sed -n '1,20p'
            curl -L -s "$ONEDRIVE_PUBLIC_URL" --range 0-511 -o /tmp/sniff.bin
          if file -b /tmp/sniff.bin | grep -qi 'html'; then
            echo "‚ùå Got HTML instead of expected data file"
            exit 1
          fi

      - name: Ingest workload (OneDrive)
        env:
          GCP_PROJECT: ${{ env.GCP_PROJECT }}
          BQ_DATASET: ${{ env.BQ_DATASET }}
          BQ_LOCATION: ${{ env.BQ_LOCATION }}
          BQ_TABLE: ${{ env.WORKLOAD_TABLE }}
          # Choose appropriate write mode: WRITE_APPEND (default) or MERGE if script supports upserts
          BQ_WRITE_MODE: WRITE_APPEND
          ONEDRIVE_PUBLIC_URL: "https://mysacstate-my.sharepoint.com/:x:/g/personal/torin_shanahan_csus_edu/EfH5izRo81tHiVlwG99DEFsBzjwhTzBzQ_1_hYKgpq_VPA?download=1"
          LOCAL_FILE_PATH: ""
        run: Rscript .github/scripts/workload_ingest.R

      - name: Check ingest success
        id: ingest_check
        run: |
          echo "‚úÖ Workload ingest completed successfully"
          echo "status=success" >> "$GITHUB_OUTPUT"

    outputs:
      status: ${{ steps.ingest_check.outputs.status }}

  check-readiness:
    runs-on: ubuntu-latest
    needs: ingest
    if: needs.ingest.outputs.status == 'success'
    steps:
      - uses: actions/checkout@v4

      - name: Auth to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
          create_credentials_file: true
          export_environment_variables: true

      - uses: google-github-actions/setup-gcloud@v2

      - name: Ensure jq present
        run: |
          if ! command -v jq >/dev/null 2>&1; then
            sudo apt-get update && sudo apt-get install -y jq
          fi

      - name: Preflight validation
        id: preflight
        shell: bash
        env:
          GCP_PROJECT: ${{ env.GCP_PROJECT }}
          BQ_DATASET: ${{ env.BQ_DATASET }}
          BQ_LOCATION: ${{ env.BQ_LOCATION }}
          WORKLOAD_TABLE: ${{ env.WORKLOAD_TABLE }}
          READINESS_TABLE: ${{ env.READINESS_TABLE }}
          ROSTER_TABLE: ${{ env.ROSTER_TABLE }}
        run: |
          set -euo pipefail
          echo "=== Preflight ==="
          for v in GCP_PROJECT BQ_DATASET BQ_LOCATION WORKLOAD_TABLE READINESS_TABLE ROSTER_TABLE; do
            eval "val=\${$v}"
            if [ -z "$val" ]; then
              echo "‚ùå $v is empty"
              exit 1
            fi
          done
          bq --location="$BQ_LOCATION" --project_id="$GCP_PROJECT" ls "$BQ_DATASET" >/dev/null
          bq --location="$BQ_LOCATION" --project_id="$GCP_PROJECT" show "${GCP_PROJECT}:${BQ_DATASET}.${WORKLOAD_TABLE}" >/dev/null
          bq --location="$BQ_LOCATION" --project_id="$GCP_PROJECT" show "${GCP_PROJECT}:${BQ_DATASET}.${READINESS_TABLE}" >/dev/null
          bq --location="$BQ_LOCATION" --project_id="$GCP_PROJECT" show "${GCP_PROJECT}:${BQ_DATASET}.${ROSTER_TABLE}" >/dev/null

      - name: Validate roster mapping table
        shell: bash
        env:
          GCP_PROJECT: ${{ env.GCP_PROJECT }}
          BQ_DATASET: ${{ env.BQ_DATASET }}
          BQ_LOCATION: ${{ env.BQ_LOCATION }}
          ROSTER_TABLE: ${{ env.ROSTER_TABLE }}
        run: |
          set -euo pipefail
          CNT=$(bq --location="$BQ_LOCATION" --project_id="$GCP_PROJECT" query --use_legacy_sql=false --format=csv \
            "SELECT COUNT(*) FROM \`${GCP_PROJECT}.${BQ_DATASET}.${ROSTER_TABLE}\`" | tail -n1)
          if [ "$CNT" -eq 0 ]; then
            echo "‚ùå roster_mapping is empty"
            exit 1
          fi
          SCHEMA=$(bq --location="$BQ_LOCATION" --project_id="$GCP_PROJECT" show --schema --format=prettyjson "${GCP_PROJECT}:${BQ_DATASET}.${ROSTER_TABLE}")
          echo "$SCHEMA" | jq -r '.[].name' | grep -q '^offical_id$' || { echo "‚ùå missing column offical_id (check spelling)"; exit 1; }
          echo "$SCHEMA" | jq -r '.[].name' | grep -q '^Vald Name$'   || { echo "‚ùå missing column 'Vald Name'"; exit 1; }

      - name: Check for matching readiness data (offical_id + date via roster mapping)
        id: check
        shell: bash
        env:
          GCP_PROJECT: ${{ env.GCP_PROJECT }}
          BQ_DATASET: ${{ env.BQ_DATASET }}
          BQ_LOCATION: ${{ env.BQ_LOCATION }}
          WORKLOAD_TABLE: ${{ env.WORKLOAD_TABLE }}
          READINESS_TABLE: ${{ env.READINESS_TABLE }}
          ROSTER_TABLE: ${{ env.ROSTER_TABLE }}
        run: |
          set -euo pipefail
          echo "üîç Checking workload ‚Üî readiness matches (last 7 days)..."
          MATCH_QUERY="
          WITH workload AS (
            SELECT DISTINCT
              TRIM(CAST(roster_name AS STRING)) AS offical_id,
              DATE(date) AS date
            FROM \`${GCP_PROJECT}.${BQ_DATASET}.${WORKLOAD_TABLE}\`
            WHERE date >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY)
          ),
          readiness_raw AS (
            SELECT
              DATE(date) AS date,
              LOWER(TRIM(full_name)) AS vald_full_name_norm,
              SAFE_DIVIDE(
                IFNULL(CAST(jump_height_readiness AS FLOAT64), 0) +
                IFNULL(CAST(epf_readiness          AS FLOAT64), 0) +
                IFNULL(CAST(rsi_readiness          AS FLOAT64), 0),
                NULLIF(
                  IF(jump_height_readiness IS NULL, 0, 1) +
                  IF(epf_readiness          IS NULL, 0, 1) +
                  IF(rsi_readiness          IS NULL, 0, 1),
                  0
                )
              ) AS readiness
            FROM \`${GCP_PROJECT}.${BQ_DATASET}.${READINESS_TABLE}\`
            WHERE date >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY)
          ),
          roster_norm AS (
            SELECT
              TRIM(CAST(offical_id AS STRING)) AS offical_id,
              LOWER(TRIM(\`Vald Name\`)) AS vald_full_name_norm
            FROM \`${GCP_PROJECT}.${BQ_DATASET}.${ROSTER_TABLE}\`
          ),
          readiness_by_id AS (
            SELECT
              rmap.offical_id,
              rr.date,
              rr.readiness
            FROM readiness_raw rr
            JOIN roster_norm rmap
              ON rmap.vald_full_name_norm = rr.vald_full_name_norm
          )
          SELECT
            COUNT(DISTINCT w.offical_id) AS athletes_with_matches,
            COUNT(*) AS total_matches,
            MIN(w.date) AS earliest_match,
            MAX(w.date) AS latest_match
          FROM workload w
          JOIN readiness_by_id rd
            ON rd.offical_id = w.offical_id
           AND rd.date       = w.date
          "
          if ! RES=$(bq --location="$BQ_LOCATION" --project_id="$GCP_PROJECT" query --use_legacy_sql=false --format=json "$MATCH_QUERY" 2>&1); then
            echo "‚ùå BigQuery match query failed"
            echo "$RES"
            echo "has_matches=false" >> "$GITHUB_OUTPUT"
            echo "reason=query_failed" >> "$GITHUB_OUTPUT"
            exit 1
          fi
          ATH=$(echo "$RES" | jq -r '.[0].athletes_with_matches // 0')
          MAT=$(echo "$RES" | jq -r '.[0].total_matches // 0')
          EAR=$(echo "$RES" | jq -r '.[0].earliest_match // "none"')
          LAT=$(echo "$RES" | jq -r '.[0].latest_match // "none"')
          echo "üìä Athletes matched: $ATH | Total matches: $MAT | Range: $EAR ‚Üí $LAT"
          if [ "$MAT" -gt 0 ]; then
            echo "has_matches=true" >> "$GITHUB_OUTPUT"
            echo "match_count=$MAT" >> "$GITHUB_OUTPUT"
            echo "athlete_count=$ATH" >> "$GITHUB_OUTPUT"
          else
            echo "has_matches=false" >> "$GITHUB_OUTPUT"
            echo "reason=no_readiness_match" >> "$GITHUB_OUTPUT"
          fi

    outputs:
      has_matches: ${{ steps.check.outputs.has_matches }}
      match_count: ${{ steps.check.outputs.match_count }}
      athlete_count: ${{ steps.check.outputs.athlete_count }}
      reason: ${{ steps.check.outputs.reason }}

  train-models:
    runs-on: ubuntu-latest
    needs: [ingest, check-readiness]
    if: |
      needs.ingest.outputs.status == 'success' &&
      needs.check-readiness.outputs.has_matches == 'true' &&
      github.event.inputs.skip_training != 'true'
    steps:
      - uses: actions/checkout@v4

      - name: Auth to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
          create_credentials_file: true
          export_environment_variables: true

      - uses: google-github-actions/setup-gcloud@v2

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Python deps (for sklearn models)
        run: |
          python -m pip install --upgrade pip
          pip install scikit-learn==1.5.1 numpy==1.26.4

      - uses: r-lib/actions/setup-r@v2
        with:
          use-public-rspm: true

      - uses: r-lib/actions/setup-r-dependencies@v2
        with:
          cache-version: 1
          extra-packages: |
            any::bigrquery
            any::DBI
            any::dplyr
            any::tidyr
            any::data.table
            any::lubridate
            any::slider
            any::stringr
            any::gargle
            any::glue
            any::digest
            any::googleCloudStorageR
            any::glmnet
            any::bnlearn
            any::reticulate

      - name: System libs
        run: |
          sudo apt-get update
          sudo apt-get install -y libcurl4-openssl-dev libssl-dev libxml2-dev jq

      - name: Run model training
        env:
          GCP_PROJECT: ${{ env.GCP_PROJECT }}
          BQ_DATASET: ${{ env.BQ_DATASET }}
          BQ_LOCATION: ${{ env.BQ_LOCATION }}
          TEAM_NAME: ${{ env.TEAM_NAME }}

          WORKLOAD_TABLE: ${{ env.WORKLOAD_TABLE }}
          READINESS_TABLE: ${{ env.READINESS_TABLE }}
          ROSTER_TABLE: ${{ env.ROSTER_TABLE }}
          PREDICTIONS_TABLE: ${{ env.PREDICTIONS_TABLE }}

          START_DATE: ${{ github.event.inputs.start_date || '2025-06-01' }}
          END_DATE: ${{ github.event.inputs.end_date || '2025-12-31' }}
          TRAIN_FRACTION: "0.80"
          MIN_TRAIN_OBS: "3"

          HAS_MATCHES: ${{ needs.check-readiness.outputs.has_matches }}
          MATCH_LOOKBACK_DAYS: "7"
          SKIP_TRAINING: ${{ github.event.inputs.skip_training || 'false' }}

          GCS_BUCKET: ${{ secrets.GCS_BUCKET }}
        run: |
          set -euo pipefail
          if [ "$HAS_MATCHES" != "true" ]; then
            echo "No matches present; aborting training defensively."
            exit 0
          fi
          Rscript ".github/scripts/readiness_models_cloud.R"

      - name: Show today's training summary (best-effort)
        if: success()
        env:
          GCP_PROJECT: ${{ env.GCP_PROJECT }}
          BQ_DATASET: ${{ env.BQ_DATASET }}
          BQ_LOCATION: ${{ env.BQ_LOCATION }}
        run: |
          echo "üìà Latest Models:"
          bq --location="$BQ_LOCATION" --project_id="$GCP_PROJECT" query --use_legacy_sql=false --max_rows=10 \
            "SELECT 
               athlete_id,
               roster_name,
               model_type,
               ROUND(primary_rmse, 3) AS rmse,
               n_train,
               FORMAT_TIMESTAMP('%H:%M', trained_at) AS time
             FROM \`${GCP_PROJECT}.${BQ_DATASET}.model_training_summary\`
             WHERE DATE(trained_at) = CURRENT_DATE()
             ORDER BY trained_at DESC
             LIMIT 10" || echo "No training results yet"

          echo ""
          echo "üìä Today's Training Stats:"
            bq --location="$BQ_LOCATION" --project_id="$GCP_PROJECT" query --use_legacy_sql=false \
            "SELECT 
               COUNT(DISTINCT athlete_id) AS athletes_trained,
               COUNT(*) AS total_models,
               ROUND(AVG(primary_rmse), 3) AS avg_rmse,
               FORMAT_TIMESTAMP('%Y-%m-%d %H:%M', MAX(trained_at)) AS last_run
             FROM \`${GCP_PROJECT}.${BQ_DATASET}.model_training_summary\`
             WHERE DATE(trained_at) = CURRENT_DATE()" || echo "No stats available"

  summary:
    runs-on: ubuntu-latest
    needs: [ingest, check-readiness, train-models]
    if: always()
    steps:
      - name: Pipeline Summary
        env:
          HAS_MATCHES: ${{ needs.check-readiness.outputs.has_matches }}
          MATCH_COUNT: ${{ needs.check-readiness.outputs.match_count }}
          ATH_COUNT: ${{ needs.check-readiness.outputs.athlete_count }}
        run: |
          echo "=============================================================="
          echo "    WORKLOAD & MODEL PIPELINE SUMMARY"
          echo "=============================================================="
          echo ""
          echo "üîπ Workload Ingest:     ${{ needs.ingest.result }}"
          echo "üîπ Readiness Check:     ${{ needs.check-readiness.result }}"
          echo "üîπ Model Training:      ${{ needs.train-models.result }}"
          echo ""
          if [ "${{ needs.ingest.result }}" != "success" ]; then
            echo "‚ùå INGEST FAILED - Check workload ingest logs"
            exit 1
          elif [ "${{ needs.check-readiness.result }}" == "skipped" ]; then
            echo "‚è≠Ô∏è  PIPELINE SKIPPED - Readiness check did not run (ingest failed)"
            exit 1
          elif [ "$HAS_MATCHES" != "true" ]; then
            echo "‚úÖ INGEST COMPLETE - Workload data saved"
            echo "‚è≠Ô∏è  TRAINING SKIPPED - No matching readiness data found (OK)"
            exit 0
          elif [ "${{ needs.train-models.result }}" == "skipped" ]; then
            echo "‚úÖ INGEST COMPLETE"
            echo "‚úÖ READINESS CHECK - Found $MATCH_COUNT matches across $ATH_COUNT athletes"
            echo "‚è≠Ô∏è  TRAINING SKIPPED - Manual skip requested"
            exit 0
          elif [ "${{ needs.train-models.result }}" == "success" ]; then
            echo "‚úÖ PIPELINE COMPLETE - All jobs succeeded!"
            echo "üìä Matches: $MATCH_COUNT | Athletes trained: $ATH_COUNT"
            exit 0
          elif [ "${{ needs.train-models.result }}" == "failure" ]; then
            echo "‚úÖ INGEST COMPLETE"
            echo "‚úÖ READINESS CHECK - Found $MATCH_COUNT matches"
            echo "‚ùå TRAINING FAILED - See model training logs"
            exit 0
          else
            echo "‚ö†Ô∏è  UNKNOWN STATUS - Inspect individual job logs"
            exit 1
