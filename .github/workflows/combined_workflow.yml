name: Workload & Model Pipeline (Every 15 min)

# This workflow runs every 15 minutes and:
# 1. Always ingests new GPS workload data
# 2. Checks if workload data has matching readiness data
# 3. Only trains models when there's BOTH workload AND readiness data
# 
# Since readiness testing happens weekly, most runs will skip model training.
# This is expected behavior - workload data is still saved every time.

on:
  schedule:
    - cron: "*/15 * * * *"
  workflow_dispatch:
    inputs:
      skip_training:
        description: 'Skip model training (ingest only)'
        required: false
        type: boolean
        default: false
      start_date:
        description: 'Model training start date (YYYY-MM-DD)'
        required: false
        default: '2025-06-01'
      end_date:
        description: 'Model training end date (YYYY-MM-DD)'
        required: false
        default: '2025-12-31'

jobs:
  # ============================================================================
  # JOB 1: WORKLOAD INGEST (runs every time)
  # ============================================================================
  ingest:
    runs-on: ubuntu-latest
    env:
      # ---- GCP / BigQuery ----
      GCP_PROJECT: ${{ secrets.GCP_PROJECT }}
      BQ_DATASET:  ${{ secrets.BQ_DATASET }}
      BQ_LOCATION: ${{ secrets.BQ_LOCATION }}
      BQ_TABLE:    ${{ secrets.BQ_TABLE }}
      BQ_WRITE_MODE: ${{ secrets.BQ_WRITE_MODE }}
      # ---- OneDrive public link ----
      ONEDRIVE_PUBLIC_URL: ${{ vars.ONEDRIVE_PUBLIC_URL }}
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Auth to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
          create_credentials_file: true
          export_environment_variables: true
      
      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2
      
      - name: Setup R
        uses: r-lib/actions/setup-r@v2
      
      - name: Install R deps (cached)
        uses: r-lib/actions/setup-r-dependencies@v2
        with:
          use-public-rspm: true
          cache-version: 1
          extra-packages: |
            any::bigrquery
            any::DBI
            any::dplyr
            any::tidyr
            any::readr
            any::stringr
            any::purrr
            any::tibble
            any::data.table
            any::hms
            any::lubridate
            any::httr
            any::jsonlite
            any::curl
            any::gargle
            any::glue
            any::slider
            any::janitor
      
      - name: System libs
        run: |
          sudo apt-get update
          sudo apt-get install -y libcurl4-openssl-dev libssl-dev libxml2-dev
      
      - name: Run workload ingest
        run: Rscript ".github/scripts/workload_ingest.R"
      
      - name: Check ingest success
        id: ingest_check
        run: |
          if [ $? -eq 0 ]; then
            echo "âœ… Workload ingest completed successfully"
            echo "status=success" >> $GITHUB_OUTPUT
          else
            echo "âŒ Workload ingest failed"
            echo "status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi
    
    outputs:
      status: ${{ steps.ingest_check.outputs.status }}

  # ============================================================================
  # JOB 2: CHECK FOR READINESS DATA MATCH (robust error handling)
  # ============================================================================
  check-readiness:
    runs-on: ubuntu-latest
    needs: ingest
    if: needs.ingest.outputs.status == 'success'
    
    env:
      GCP_PROJECT: ${{ secrets.GCP_PROJECT }}
      BQ_DATASET:  ${{ secrets.BQ_DATASET }}
      READINESS_TABLE: ${{ vars.READINESS_TABLE }}
      WORKLOAD_TABLE: ${{ vars.WORKLOAD_TABLE }}
      ROSTER_TABLE: ${{ vars.ROSTER_TABLE }}
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Auth to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
          create_credentials_file: true
          export_environment_variables: true
      
      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2

      - name: Check for matching readiness data
        id: check
        shell: bash
        run: |
          set -euo pipefail

          # Helpful diagnostics
          bq version || true
          gcloud --version || true
          gcloud auth list || true

          echo "Using project: $GCP_PROJECT"
          if ! command -v jq >/dev/null 2>&1; then
            echo "Installing jq..."
            sudo apt-get update && sudo apt-get install -y jq
          fi

          echo "Active account:"
          gcloud auth list
          echo "Current project:"
          gcloud config get-value project

          # Quick IAM probe
          bq ls --project_id="$GCP_PROJECT" "$BQ_DATASET" || {
            echo "âŒ Cannot list dataset tables. Check IAM for the service account."
            echo "has_matches=false" >> "$GITHUB_OUTPUT"
            echo "reason=iam_failed" >> "$GITHUB_OUTPUT"
            exit 1
          }

          echo "ğŸ” Building readiness match query..."
          MATCH_QUERY="
          WITH recent_workload AS (
            SELECT DISTINCT roster_name, DATE(date) AS date
            FROM \`${GCP_PROJECT}.${BQ_DATASET}.${WORKLOAD_TABLE}\`
            WHERE date >= CURRENT_DATE() - 7
          ),
          roster_with_ids AS (
            SELECT DISTINCT 
              LOWER(TRIM(kinexon_name)) AS roster_name,
              offical_id
            FROM \`${GCP_PROJECT}.${BQ_DATASET}.${ROSTER_TABLE}\`
          ),
          readiness_recent AS (
            SELECT DISTINCT offical_id, DATE(date) AS date
            FROM \`${GCP_PROJECT}.${BQ_DATASET}.${READINESS_TABLE}\`
            WHERE date >= CURRENT_DATE() - 7
          ),
          matched AS (
            SELECT 
              w.roster_name,
              w.date,
              r.offical_id,
              rd.date AS readiness_date
            FROM recent_workload w
            JOIN roster_with_ids r 
              ON LOWER(TRIM(w.roster_name)) = r.roster_name
            JOIN readiness_recent rd
              ON r.offical_id = rd.offical_id
              AND w.date = rd.date
          )
          SELECT 
            COUNT(DISTINCT roster_name) AS athletes_with_matches,
            COUNT(*) AS total_matches,
            MIN(date) AS earliest_match,
            MAX(date) AS latest_match
          FROM matched
          "

          echo "â€“â€“â€“â€“ SQL â€“â€“â€“â€“â€“"
          echo "$MATCH_QUERY"
          echo "â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“"

          # Dry run to validate syntax/refs fast
          if ! bq query --use_legacy_sql=false --dry_run "$MATCH_QUERY" 1>/dev/null 2>&1; then
            echo "âŒ BigQuery dry run failed"
            echo "Query: $MATCH_QUERY"
            echo "has_matches=false" >> "$GITHUB_OUTPUT"
            echo "reason=query_invalid" >> "$GITHUB_OUTPUT"
            exit 1
          fi

          # Execute query
          set +e
          RESULT=$(bq query --use_legacy_sql=false --format=json "$MATCH_QUERY" 2>&1)
          BQ_EXIT=$?
          set -e

          if [ $BQ_EXIT -ne 0 ]; then
            echo "âŒ Failed to query for readiness matches"
            echo "Query: $MATCH_QUERY"
            echo "Error: $RESULT"
            echo "has_matches=false" >> "$GITHUB_OUTPUT"
            echo "reason=query_failed" >> "$GITHUB_OUTPUT"
            exit 1
          fi

          # Parse JSON
          ATHLETES=$(echo "$RESULT" | jq -r '.[0].athletes_with_matches // 0')
          MATCHES=$(echo   "$RESULT" | jq -r '.[0].total_matches // 0')
          EARLIEST=$(echo  "$RESULT" | jq -r '.[0].earliest_match // "none"')
          LATEST=$(echo    "$RESULT" | jq -r '.[0].latest_match // "none"')

          echo "ğŸ“Š Match Results:"
          echo "  â€¢ Athletes with matches: $ATHLETES"
          echo "  â€¢ Total matches: $MATCHES"
          echo "  â€¢ Date range: $EARLIEST to $LATEST"

          if [ "$MATCHES" -gt 0 ]; then
            echo "âœ… Found matching data - models can be trained"
            echo "has_matches=true" >> "$GITHUB_OUTPUT"
            echo "match_count=$MATCHES" >> "$GITHUB_OUTPUT"
            echo "athlete_count=$ATHLETES" >> "$GITHUB_OUTPUT"
          else
            echo "â­ï¸  No matching readiness data found - skipping model training"
            echo "has_matches=false" >> "$GITHUB_OUTPUT"
            echo "reason=no_readiness_match" >> "$GITHUB_OUTPUT"
          fi
    
    outputs:
      has_matches: ${{ steps.check.outputs.has_matches }}
      match_count: ${{ steps.check.outputs.match_count }}
      athlete_count: ${{ steps.check.outputs.athlete_count }}
      reason: ${{ steps.check.outputs.reason }}

  # ============================================================================
  # JOB 3: MODEL TRAINING (runs only if readiness data matches)
  # ============================================================================
  train-models:
    runs-on: ubuntu-latest
    needs: [ingest, check-readiness]
    # Only run if ingest succeeded AND we have matching readiness data AND user didn't skip
    if: |
      needs.ingest.outputs.status == 'success' && 
      needs.check-readiness.outputs.has_matches == 'true' &&
      github.event.inputs.skip_training != 'true'
    
    env:
      # ---- GCP / BigQuery ----
      GCP_PROJECT: ${{ secrets.GCP_PROJECT }}
      BQ_DATASET:  ${{ secrets.BQ_DATASET }}
      BQ_LOCATION: ${{ secrets.BQ_LOCATION }}
      GCS_BUCKET:  ${{ secrets.GCS_BUCKET }}
      TEAM_NAME:   ${{ vars.TEAM_NAME }}
      
      # ---- Table names ----
      WORKLOAD_TABLE:    ${{ vars.WORKLOAD_TABLE }}
      READINESS_TABLE:   ${{ vars.READINESS_TABLE }}
      ROSTER_TABLE:      ${{ vars.ROSTER_TABLE }}
      PREDICTIONS_TABLE: ${{ vars.PREDICTIONS_TABLE }}
      
      # ---- Model training config ----
      START_DATE:     ${{ github.event.inputs.start_date || '2025-06-01' }}
      END_DATE:       ${{ github.event.inputs.end_date || '2025-12-31' }}
      TRAIN_FRACTION: '0.80'
      MIN_TRAIN_OBS:  '3'

      # ---- NEW: wire Job 2 decision & manual skip into the R script ----
      HAS_MATCHES:           ${{ needs.check-readiness.outputs.has_matches }}
      MATCH_LOOKBACK_DAYS:   '7'   # optional: used only if HAS_MATCHES not provided
      SKIP_TRAINING:         ${{ github.event.inputs.skip_training || 'false' }}
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Auth to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
          create_credentials_file: true
          export_environment_variables: true
      
      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install scikit-learn==1.5.1 numpy==1.26.4
      
      - name: Setup R
        uses: r-lib/actions/setup-r@v2
      
      - name: Install R deps (cached)
        uses: r-lib/actions/setup-r-dependencies@v2
        with:
          use-public-rspm: true
          cache-version: 1
          extra-packages: |
            any::bigrquery
            any::DBI
            any::dplyr
            any::tidyr
            any::data.table
            any::lubridate
            any::slider
            any::stringr
            any::gargle
            any::glue
            any::digest
            any::googleCloudStorageR
            any::glmnet
            any::bnlearn
            any::reticulate
      
      - name: System libs
        run: |
          sudo apt-get update
          sudo apt-get install -y libcurl4-openssl-dev libssl-dev libxml2-dev
      
      - name: Run model training
        run: Rscript ".github/scripts/readiness_models.R"
      
      - name: Check training success
        if: success()
        run: |
          echo "âœ… Model training completed successfully"
          echo ""
          echo "ğŸ“Š Trained on ${{ needs.check-readiness.outputs.match_count }} workload-readiness matches"
          echo "   across ${{ needs.check-readiness.outputs.athlete_count }} athletes"
          
          # Query recent results
          gcloud auth activate-service-account --key-file=$GOOGLE_APPLICATION_CREDENTIALS
          
          echo ""
          echo "ğŸ“ˆ Latest Models:"
          b
q query --use_legacy_sql=false --max_rows=10 \
            "SELECT 
               athlete_id,
               roster_name,
               model_type,
               ROUND(primary_rmse, 3) as rmse,
               n_train,
               FORMAT_TIMESTAMP('%H:%M', trained_at) as time
             FROM \`${GCP_PROJECT}.${BQ_DATASET}.model_training_summary\`
             WHERE DATE(trained_at) = CURRENT_DATE()
             ORDER BY trained_at DESC
             LIMIT 10" || echo "No training results yet"
          
          echo ""
          echo "ğŸ“Š Today's Training Stats:"
          bq query --use_legacy_sql=false \
            "SELECT 
               COUNT(DISTINCT athlete_id) as athletes_trained,
               COUNT(*) as total_models,
               ROUND(AVG(primary_rmse), 3) as avg_rmse,
               FORMAT_TIMESTAMP('%Y-%m-%d %H:%M', MAX(trained_at)) as last_run
             FROM \`${GCP_PROJECT}.${BQ_DATASET}.model_training_summary\`
             WHERE DATE(trained_at) = CURRENT_DATE()" || echo "No stats available"
      
      - name: Check for failures
        if: failure()
        run: |
          echo "âŒ Model training failed"
          echo "Check logs in BigQuery: ${GCP_PROJECT}.${BQ_DATASET}.model_training_log"
          
          # Try to show recent errors
          gcloud auth activate-service-account --key-file=$GOOGLE_APPLICATION_CREDENTIALS || true
          bq query --use_legacy_sql=false --max_rows=10 \
            "SELECT 
               FORMAT_TIMESTAMP('%H:%M:%S', timestamp) as time,
               level, 
               message
             FROM \`${GCP_PROJECT}.${BQ_DATASET}.model_training_log\`
             WHERE level = 'ERROR' 
               AND DATE(timestamp) = CURRENT_DATE()
             ORDER BY timestamp DESC
             LIMIT 10" || echo "Could not query error logs"

  # ============================================================================
  # JOB 4: SUMMARY (runs after all jobs, always)
  # ============================================================================
  summary:
    runs-on: ubuntu-latest
    needs: [ingest, check-readiness, train-models]
    if: always()
    
    steps:
      - name: Pipeline Summary
        run: |
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "    WORKLOAD & MODEL PIPELINE SUMMARY"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          echo "ğŸ”¹ Workload Ingest:     ${{ needs.ingest.result }}"
          echo "ğŸ”¹ Readiness Check:     ${{ needs.check-readiness.result }}"
          echo "ğŸ”¹ Model Training:      ${{ needs.train-models.result }}"
          echo ""
          
          # Detailed status explanation
          if [ "${{ needs.ingest.result }}" != "success" ]; then
            echo "âŒ INGEST FAILED - Check workload ingest logs"
            exit 1
          
          elif [ "${{ needs.check-readiness.result }}" == "skipped" ]; then
            echo "â­ï¸  PIPELINE SKIPPED - Ingest failed, no readiness check performed"
            exit 1
          
          elif [ "${{ needs.check-readiness.outputs.has_matches }}" != "true" ]; then
            echo "âœ… INGEST COMPLETE - Workload data saved"
            echo "â­ï¸  TRAINING SKIPPED - No matching readiness data found"
            echo ""
            echo "ğŸ’¡ This is normal! Readiness testing happens weekly."
            echo "   Workload data is saved and models will train when"
            echo "   new readiness data becomes available."
            exit 0
          
          elif [ "${{ needs.train-models.result }}" == "skipped" ]; then
            echo "âœ… INGEST COMPLETE - Workload data saved"
            echo "âœ… READINESS CHECK - Found ${{ needs.check-readiness.outputs.match_count }} matches"
            echo "â­ï¸  TRAINING SKIPPED - Manual skip requested"
            exit 0
          
          elif [ "${{ needs.train-models.result }}" == "success" ]; then
            echo "âœ… PIPELINE COMPLETE - All jobs succeeded!"
            echo ""
            echo "ğŸ“Š Summary:"
            echo "   â€¢ Workload data: Updated"
            echo "   â€¢ Matches found: ${{ needs.check-readiness.outputs.match_count }}"
            echo "   â€¢ Athletes trained: ${{ needs.check-readiness.outputs.athlete_count }}"
            echo "   â€¢ Models: Saved to GCS"
            echo "   â€¢ Predictions: Saved to BigQuery"
            exit 0
          
          elif [ "${{ needs.train-models.result }}" == "failure" ]; then
            echo "âœ… INGEST COMPLETE - Workload data saved"
            echo "âœ… READINESS CHECK - Found ${{ needs.check-readiness.outputs.match_count }} matches"
            echo "âŒ TRAINING FAILED - Check model training logs"
            echo ""
            echo "âš ï¸  Workload data is saved, but models couldn't be trained."
            echo "   Review error logs in BigQuery or GitHub Actions."
            exit 0
          
          else
            echo "âš ï¸  UNKNOWN STATUS - Check individual job logs"
            exit 1
          fi
