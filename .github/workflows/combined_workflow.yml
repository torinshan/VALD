name: Workload & Model Pipeline (Every 15 min)

on:
  schedule:
    - cron: "*/15 * * * *"
  workflow_dispatch:
    inputs:
      skip_training:
        description: 'Skip model training (ingest only)'
        required: false
        type: boolean
        default: false
      start_date:
        description: 'Model training start date (YYYY-MM-DD)'
        required: false
        default: '2025-06-01'
      end_date:
        description: 'Model training end date (YYYY-MM-DD)'
        required: false
        default: '2025-12-31'

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GLOBAL DEFAULTS (safe fallbacks; jobs may override)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
env:
  GCP_PROJECT: sac-vald-hub
  BQ_DATASET:  analytics
  BQ_LOCATION: US

  # Tables/views used by this workflow
  WORKLOAD_TABLE:  workload_daily
  READINESS_TABLE: ml_builder_readiness         # â† the VIEW you created
  ROSTER_TABLE:    roster_mapping               # optional (not required for name-join)
  PREDICTIONS_TABLE: readiness_predictions_byname

  # Team/bucket (needed by training script if saving artifacts)
  TEAM_NAME: sacstate-football
  # GCS_BUCKET should be set as a Secret; leave here for clarity
  # GCS_BUCKET: your-bucket-name

jobs:
  # ============================================================================
  # JOB 1: WORKLOAD INGEST (always)
  # ============================================================================
  ingest:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Auth to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
          create_credentials_file: true
          export_environment_variables: true

      - uses: google-github-actions/setup-gcloud@v2

      - uses: r-lib/actions/setup-r@v2
        with:
          use-public-rspm: true

      - uses: r-lib/actions/setup-r-dependencies@v2
        with:
          cache-version: 1
          extra-packages: |
            any::bigrquery
            any::DBI
            any::dplyr
            any::tidyr
            any::readr
            any::stringr
            any::gargle
            any::glue
            any::jsonlite

      - name: System libs
        run: |
          sudo apt-get update
          sudo apt-get install -y libcurl4-openssl-dev libssl-dev libxml2-dev jq

      - name: Run workload ingest
        env:
          GCP_PROJECT: ${{ env.GCP_PROJECT }}
          BQ_DATASET:  ${{ env.BQ_DATASET }}
          BQ_LOCATION: ${{ env.BQ_LOCATION }}
          # Your ingest script may need these (showing placeholders):
          BQ_TABLE:    ${{ env.WORKLOAD_TABLE }}
          BQ_WRITE_MODE: WRITE_APPEND
        run: Rscript ".github/scripts/workload_ingest.R"

      - name: Check ingest success
        id: ingest_check
        run: |
          echo "âœ… Workload ingest completed successfully"
          echo "status=success" >> "$GITHUB_OUTPUT"

    outputs:
      status: ${{ steps.ingest_check.outputs.status }}

  # ============================================================================
  # JOB 2: CHECK FOR READINESS DATA MATCH (by name+date, robust & graceful)
  # ============================================================================
  check-readiness:
    runs-on: ubuntu-latest
    needs: ingest
    if: needs.ingest.outputs.status == 'success'

    steps:
      - uses: actions/checkout@v4

      - name: Auth to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
          create_credentials_file: true
          export_environment_variables: true

      - uses: google-github-actions/setup-gcloud@v2

      - name: Ensure jq present
        run: |
          if ! command -v jq >/dev/null 2>&1; then
            sudo apt-get update && sudo apt-get install -y jq
          fi

      - name: Preflight: validate env & resources
        id: preflight
        shell: bash
        env:
          GCP_PROJECT: ${{ env.GCP_PROJECT }}
          BQ_DATASET:  ${{ env.BQ_DATASET }}
          BQ_LOCATION: ${{ env.BQ_LOCATION }}
          WORKLOAD_TABLE:  ${{ env.WORKLOAD_TABLE }}
          READINESS_TABLE: ${{ env.READINESS_TABLE }}
        run: |
          set -euo pipefail

          echo "Env:"
          echo "  GCP_PROJECT=$GCP_PROJECT"
          echo "  BQ_DATASET=$BQ_DATASET"
          echo "  BQ_LOCATION=$BQ_LOCATION"
          echo "  WORKLOAD_TABLE=$WORKLOAD_TABLE"
          echo "  READINESS_TABLE=$READINESS_TABLE"

          : "${GCP_PROJECT:?GCP_PROJECT is required}"
          : "${BQ_DATASET:?BQ_DATASET is required}"
          : "${BQ_LOCATION:?BQ_LOCATION is required}"
          : "${WORKLOAD_TABLE:?WORKLOAD_TABLE is required}"
          : "${READINESS_TABLE:?READINESS_TABLE is required}"

          echo "Checking dataset existsâ€¦"
          bq --location="$BQ_LOCATION" --project_id="$GCP_PROJECT" ls "$BQ_DATASET" >/dev/null

          echo "Checking workload table existsâ€¦"
          bq --location="$BQ_LOCATION" --project_id="$GCP_PROJECT" show \
            "${GCP_PROJECT}:${BQ_DATASET}.${WORKLOAD_TABLE}" >/dev/null

          echo "Checking readiness view/table existsâ€¦"
          bq --location="$BQ_LOCATION" --project_id="$GCP_PROJECT" show \
            "${GCP_PROJECT}:${BQ_DATASET}.${READINESS_TABLE}" >/dev/null

          echo "Preflight OK"

      - name: Check for matching readiness data (normalized name + date)
        id: check
        shell: bash
        env:
          GCP_PROJECT: ${{ env.GCP_PROJECT }}
          BQ_DATASET:  ${{ env.BQ_DATASET }}
          BQ_LOCATION: ${{ env.BQ_LOCATION }}
          WORKLOAD_TABLE:  ${{ env.WORKLOAD_TABLE }}
          READINESS_TABLE: ${{ env.READINESS_TABLE }}
        run: |
          set -euo pipefail
          echo "ğŸ” Checking workload â†” readiness matches (by normalized name & date)â€¦"

          MATCH_QUERY="
          WITH recent_workload AS (
            SELECT DISTINCT
              LOWER(TRIM(roster_name)) AS name_norm,
              DATE(date) AS date
            FROM \`${GCP_PROJECT}.${BQ_DATASET}.${WORKLOAD_TABLE}\`
            WHERE date >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY)
          ),
          readiness_recent AS (
            SELECT DISTINCT
              full_name_norm AS name_norm,
              DATE(date) AS date
            FROM \`${GCP_PROJECT}.${BQ_DATASET}.${READINESS_TABLE}\`
            WHERE date >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY)
          ),
          matched AS (
            SELECT w.name_norm, w.date
            FROM recent_workload w
            JOIN readiness_recent r
              ON r.name_norm = w.name_norm
             AND r.date = w.date
          )
          SELECT
            COUNT(DISTINCT name_norm) AS athletes_with_matches,
            COUNT(*) AS total_matches,
            MIN(date) AS earliest_match,
            MAX(date) AS latest_match
          FROM matched
          "

          echo "â€“â€“â€“â€“ SQL â€“â€“â€“â€“"
          echo "$MATCH_QUERY"
          echo "â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“"

          echo "Dry runâ€¦"
          if ! DRYRUN_OUT="$(bq --location="$BQ_LOCATION" --project_id="$GCP_PROJECT" query \
                --use_legacy_sql=false --dry_run "$MATCH_QUERY" 2>&1)"; then
            echo "âŒ BigQuery dry run failed"
            echo "$DRYRUN_OUT"
            echo "has_matches=false" >> "$GITHUB_OUTPUT"
            echo "reason=query_invalid" >> "$GITHUB_OUTPUT"
            exit 1   # real error: invalid SQL / missing refs
          fi
          echo "âœ… Dry run OK"

          echo "Executingâ€¦"
          if ! RESULT_JSON="$(bq --location="$BQ_LOCATION" --project_id="$GCP_PROJECT" query \
                --use_legacy_sql=false --format=json "$MATCH_QUERY" 2>&1)"; then
            echo "âŒ BigQuery execution failed"
            echo "$RESULT_JSON"
            echo "has_matches=false" >> "$GITHUB_OUTPUT"
            echo "reason=query_failed" >> "$GITHUB_OUTPUT"
            exit 1   # real error at execution time
          fi

          ATHLETES="$(echo "$RESULT_JSON" | jq -r '.[0].athletes_with_matches // 0')"
          MATCHES="$(echo   "$RESULT_JSON" | jq -r '.[0].total_matches // 0')"
          EARLIEST="$(echo  "$RESULT_JSON" | jq -r '.[0].earliest_match // "none"')"
          LATEST="$(echo    "$RESULT_JSON" | jq -r '.[0].latest_match // "none"')"

          echo "ğŸ“Š Result:"
          echo "  â€¢ Athletes with matches: $ATHLETES"
          echo "  â€¢ Total matches: $MATCHES"
          echo "  â€¢ Date range: $EARLIEST â†’ $LATEST"

          if [ "$MATCHES" -gt 0 ]; then
            echo "âœ… Found matching data â€“ models can train"
            echo "has_matches=true" >> "$GITHUB_OUTPUT"
            echo "match_count=$MATCHES" >> "$GITHUB_OUTPUT"
            echo "athlete_count=$ATHLETES" >> "$GITHUB_OUTPUT"
            exit 0
          else
            echo "â­ï¸  No matching readiness data â€“ training will be skipped (this is OK)"
            echo "has_matches=false" >> "$GITHUB_OUTPUT"
            echo "reason=no_readiness_match" >> "$GITHUB_OUTPUT"
            exit 0
          fi

    outputs:
      has_matches:  ${{ steps.check.outputs.has_matches }}
      match_count:  ${{ steps.check.outputs.match_count }}
      athlete_count:${{ steps.check.outputs.athlete_count }}
      reason:       ${{ steps.check.outputs.reason }}

  # ============================================================================
  # JOB 3: MODEL TRAINING (only if matches found and not manually skipped)
  # ============================================================================
  train-models:
    runs-on: ubuntu-latest
    needs: [ingest, check-readiness]
    if: |
      needs.ingest.outputs.status == 'success' &&
      needs.check-readiness.outputs.has_matches == 'true' &&
      github.event.inputs.skip_training != 'true'

    steps:
      - uses: actions/checkout@v4

      - name: Auth to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
          create_credentials_file: true
          export_environment_variables: true

      - uses: google-github-actions/setup-gcloud@v2

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Python deps (for sklearn models)
        run: |
          python -m pip install --upgrade pip
          pip install scikit-learn==1.5.1 numpy==1.26.4

      - uses: r-lib/actions/setup-r@v2
        with:
          use-public-rspm: true

      - uses: r-lib/actions/setup-r-dependencies@v2
        with:
          cache-version: 1
          extra-packages: |
            any::bigrquery
            any::DBI
            any::dplyr
            any::tidyr
            any::data.table
            any::lubridate
            any::slider
            any::stringr
            any::gargle
            any::glue
            any::digest
            any::googleCloudStorageR
            any::glmnet
            any::bnlearn
            any::reticulate

      - name: System libs
        run: |
          sudo apt-get update
          sudo apt-get install -y libcurl4-openssl-dev libssl-dev libxml2-dev jq

      - name: Run model training
        env:
          GCP_PROJECT: ${{ env.GCP_PROJECT }}
          BQ_DATASET:  ${{ env.BQ_DATASET }}
          BQ_LOCATION: ${{ env.BQ_LOCATION }}
          GCS_BUCKET:  ${{ secrets.GCS_BUCKET }}
          TEAM_NAME:   ${{ env.TEAM_NAME }}

          WORKLOAD_TABLE:    ${{ env.WORKLOAD_TABLE }}
          READINESS_TABLE:   ${{ env.READINESS_TABLE }}  # name-based view
          ROSTER_TABLE:      ${{ env.ROSTER_TABLE }}     # optional; script can ignore if name-join

          PREDICTIONS_TABLE: ${{ env.PREDICTIONS_TABLE }}

          START_DATE:        ${{ github.event.inputs.start_date || '2025-06-01' }}
          END_DATE:          ${{ github.event.inputs.end_date   || '2025-12-31' }}
          TRAIN_FRACTION:    '0.80'
          MIN_TRAIN_OBS:     '3'

          HAS_MATCHES:       ${{ needs.check-readiness.outputs.has_matches }}
          MATCH_LOOKBACK_DAYS: '7'
          SKIP_TRAINING:     ${{ github.event.inputs.skip_training || 'false' }}
        run: Rscript ".github/scripts/readiness_models.R"

      - name: Show todayâ€™s training summary (best-effort)
        if: success()
        env:
          GCP_PROJECT: ${{ env.GCP_PROJECT }}
          BQ_DATASET:  ${{ env.BQ_DATASET }}
          BQ_LOCATION: ${{ env.BQ_LOCATION }}
        run: |
          echo ""
          echo "ğŸ“ˆ Latest Models:"
          bq --location="$BQ_LOCATION" --project_id="$GCP_PROJECT" query --use_legacy_sql=false --max_rows=10 \
            "SELECT 
               athlete_id    AS athlete,   -- if your script writes name-based, this may be athlete_key
               roster_name,
               model_type,
               ROUND(primary_rmse, 3) as rmse,
               n_train,
               FORMAT_TIMESTAMP('%H:%M', trained_at) as time
             FROM \`${GCP_PROJECT}.${BQ_DATASET}.model_training_summary\`
             WHERE DATE(trained_at) = CURRENT_DATE()
             ORDER BY trained_at DESC
             LIMIT 10" || echo "No training results yet"

          echo ""
          echo "ğŸ“Š Today's Training Stats:"
          bq --location="$BQ_LOCATION" --project_id="$GCP_PROJECT" query --use_legacy_sql=false \
            "SELECT 
               COUNT(DISTINCT athlete_id) as athletes_trained,
               COUNT(*) as total_models,
               ROUND(AVG(primary_rmse), 3) as avg_rmse,
               FORMAT_TIMESTAMP('%Y-%m-%d %H:%M', MAX(trained_at)) as last_run
             FROM \`${GCP_PROJECT}.${BQ_DATASET}.model_training_summary\`
             WHERE DATE(trained_at) = CURRENT_DATE()" || echo "No stats available"

  # ============================================================================
  # JOB 4: SUMMARY (always)
  # ============================================================================
  summary:
    runs-on: ubuntu-latest
    needs: [ingest, check-readiness, train-models]
    if: always()
    steps:
      - name: Pipeline Summary
        env:
          HAS_MATCHES:  ${{ needs.check-readiness.outputs.has_matches }}
          MATCH_COUNT:  ${{ needs.check-readiness.outputs.match_count }}
          ATH_COUNT:    ${{ needs.check-readiness.outputs.athlete_count }}
        run: |
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "    WORKLOAD & MODEL PIPELINE SUMMARY"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          echo "ğŸ”¹ Workload Ingest:     ${{ needs.ingest.result }}"
          echo "ğŸ”¹ Readiness Check:     ${{ needs.check-readiness.result }}"
          echo "ğŸ”¹ Model Training:      ${{ needs.train-models.result }}"
          echo ""

          if [ "${{ needs.ingest.result }}" != "success" ]; then
            echo "âŒ INGEST FAILED - Check workload ingest logs"
            exit 1

          elif [ "${{ needs.check-readiness.result }}" == "skipped" ]; then
            echo "â­ï¸  PIPELINE SKIPPED - Ingest failed, no readiness check performed"
            exit 1

          elif [ "$HAS_MATCHES" != "true" ]; then
            echo "âœ… INGEST COMPLETE - Workload data saved"
            echo "â­ï¸  TRAINING SKIPPED - No matching readiness data found (OK)"
            exit 0

          elif [ "${{ needs.train-models.result }}" == "skipped" ]; then
            echo "âœ… INGEST COMPLETE - Workload data saved"
            echo "âœ… READINESS CHECK - Found $MATCH_COUNT matches across $ATH_COUNT athletes"
            echo "â­ï¸  TRAINING SKIPPED - Manual skip requested"
            exit 0

          elif [ "${{ needs.train-models.result }}" == "success" ]; then
            echo "âœ… PIPELINE COMPLETE - All jobs succeeded!"
            echo ""
            echo "ğŸ“Š Summary:"
            echo "   â€¢ Matches found: $MATCH_COUNT"
            echo "   â€¢ Athletes trained: $ATH_COUNT"
            exit 0

          elif [ "${{ needs.train-models.result }}" == "failure" ]; then
            echo "âœ… INGEST COMPLETE - Workload data saved"
            echo "âœ… READINESS CHECK - Found $MATCH_COUNT matches"
            echo "âŒ TRAINING FAILED - Check model training logs"
            exit 0

          else
            echo "âš ï¸  UNKNOWN STATUS - Check individual job logs"
            exit 1
